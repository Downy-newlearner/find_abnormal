{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_class_v2 import *\n",
    "\n",
    "train = pd.read_csv('C:/lg_capstone/find_abnormal/data/train_begin.csv')\n",
    "test = pd.read_csv('C:/lg_capstone/find_abnormal/data/test_begin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_final_preprocessing(class_instance):\n",
    "    all_data = class_instance.data.copy()\n",
    "\n",
    "    train_data = all_data[all_data['target'].notnull()]\n",
    "    test_data = all_data[all_data['target'].isnull()]\n",
    "\n",
    "    X_train, y_train = class_instance.final_preprocessing(train_data)\n",
    "    X_test, _ = class_instance.final_preprocessing(test_data)\n",
    "\n",
    "    # X_train, X_test에서 'Set ID' 컬럼 삭제\n",
    "    X_train = X_train.drop('Set ID', axis=1)\n",
    "    Set_ID_for_submission = X_test['Set ID']\n",
    "    X_test = X_test.drop('Set ID', axis=1)\n",
    "\n",
    "    # X_test의 컬럼 순서 맞추기\n",
    "    X_test = X_test[X_train.columns]\n",
    "\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train , y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # SMOTE 적용\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, X_test, Set_ID_for_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class_v2.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diff_test['target'] = 'AbNormal'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing - dam\n",
      "preprocessing - fill1\n",
      "preprocessing - fill2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class_v2.py:396: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].replace(304.8, 305.0, inplace=True) # 304.8을 305.0으로 대체\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class_v2.py:397: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'].replace(692.8, 694.0, inplace=True) # 692.8을 694.0으로 대체\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing - autoclave\n"
     ]
    }
   ],
   "source": [
    "preprocessing = Preprocessing(train, test)\n",
    "preprocessing.dam()\n",
    "preprocessing.fill1()\n",
    "preprocessing.fill2()\n",
    "preprocessing.autoclave()\n",
    "\n",
    "\n",
    "submission_diff = preprocessing.submission_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final preprocessing\n",
      "라벨 인코딩 된 객체형 컬럼: Dispense Volume Collect Result_Fill1\n",
      "라벨 인코딩 된 객체형 컬럼: HEAD NORMAL COORDINATE X AXIS(1, 2, 3)_Fill1\n",
      "라벨 인코딩 된 객체형 컬럼: CURE TRACK POSITION X_Fill2\n",
      "라벨 인코딩 된 객체형 컬럼: HEAD NORMAL COORDINATE X AXIS_Fill2\n",
      "dropped에 추가된 컬럼:  Set ID\n",
      "dropped에 추가된 컬럼:  HEAD NORMAL COORDINATE X AXIS(1, 2, 3)_Fill1\n",
      "dropped에 추가된 컬럼:  Dispense Volume Collect Result_Fill1\n",
      "X shape:  (40413, 72)\n",
      "y shape:  (40413,)\n",
      "Final preprocessing\n",
      "라벨 인코딩 된 객체형 컬럼: Dispense Volume Collect Result_Fill1\n",
      "라벨 인코딩 된 객체형 컬럼: HEAD NORMAL COORDINATE X AXIS(1, 2, 3)_Fill1\n",
      "라벨 인코딩 된 객체형 컬럼: CURE TRACK POSITION X_Fill2\n",
      "라벨 인코딩 된 객체형 컬럼: HEAD NORMAL COORDINATE X AXIS_Fill2\n",
      "dropped에 추가된 컬럼:  Set ID\n",
      "dropped에 추가된 컬럼:  HEAD NORMAL COORDINATE X AXIS(1, 2, 3)_Fill1\n",
      "dropped에 추가된 컬럼:  Dispense Volume Collect Result_Fill1\n",
      "X shape:  (17333, 72)\n",
      "y shape:  (17333,)\n",
      "Empty DataFrame\n",
      "Columns: [Equipment_Dam, Model.Suffix_Dam, Workorder_Dam, DISCHARGED SPEED OF RESIN Collect Result_Dam, DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam, DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam, DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam, Dispense Volume(Stage1) Collect Result_Dam, Dispense Volume(Stage2) Collect Result_Dam, Dispense Volume(Stage3) Collect Result_Dam, HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam, HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam, HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam, HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam, HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam, HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam, HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam, HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam, HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam, Head Clean Position Z Collect Result_Dam, Head Purge Position Z Collect Result_Dam, Head Zero Position Y Collect Result_Dam, Head Zero Position Z Collect Result_Dam, Machine Tact time Collect Result_Dam, PalletID Collect Result_Dam, Production Qty Collect Result_Dam, Receip No Collect Result_Dam, THICKNESS 1 Collect Result_Dam, THICKNESS 2 Collect Result_Dam, THICKNESS 3 Collect Result_Dam, 1st Pressure Collect Result_AutoClave, 1st Pressure 1st Pressure Unit Time_AutoClave, 2nd Pressure Collect Result_AutoClave, 2nd Pressure Unit Time_AutoClave, 3rd Pressure Collect Result_AutoClave, 3rd Pressure Unit Time_AutoClave, Chamber Temp. Collect Result_AutoClave, Chamber Temp. Unit Time_AutoClave, Chamber Temp. Judge Value_AutoClave, GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave, Head Purge Position Z Collect Result_Fill1, Machine Tact time Collect Result_Fill1, CURE END POSITION Z Collect Result_Fill2, CURE SPEED Collect Result_Fill2, CURE START POSITION Z Collect Result_Fill2, Head Purge Position Z Collect Result_Fill2, Machine Tact time Collect Result_Fill2, Stage1_Distance_Speed_StdDev, Stage2_Distance_Speed_StdDev, Stage3_Distance_Speed_StdDev, Average Stage1 CL Distance Speed Collect Result_Dam, Average Stage2 CL Distance Speed Collect Result_Dam, Average Stage3 CL Distance Speed Collect Result_Dam, Speed_Time_Interaction_Stage1 Result_Dam, Speed_Time_Interaction_Stage2 Result_Dam, Speed_Time_Interaction_Stage3 Result_Dam, Total Speed_Time Result_Dam, Total_Dispense_Volume Result_Dam, CURE POSITION X Collect Result_Dam, CURE POSITION Z Collect Result_Dam, CURE DT X Collect Result_Dam, CURE DT Z Collect Result_Dam, THICKNESS_Range_Collect_Result_Dam, HEAD NORMAL COORDINATE Y AXIS(1, 2, 3), HEAD NORMAL COORDINATE Z AXIS(1, 2, 3), CURE TRACK POSITION X_Fill2, HEAD NORMAL COORDINATE X AXIS_Fill2, HEAD NORMAL COORDINATE Y AXIS_Fill2, HEAD NORMAL COORDINATE Z AXIS_Fill2, HEAD NORMAL COORDINATE X AXIS(1, 2, 3)_Fill1, Dispense Volume Collect Result_Fill1]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val, X_test, Set_ID = apply_final_preprocessing(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 모델 성능\n",
      "Accuracy: 0.9465544970926636\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6364    0.0476    0.0886       441\n",
      "           1     0.9478    0.9984    0.9725      7642\n",
      "\n",
      "    accuracy                         0.9466      8083\n",
      "   macro avg     0.7921    0.5230    0.5305      8083\n",
      "weighted avg     0.9308    0.9466    0.9242      8083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. SMOTE를 적용하여 학습한 랜덤 포레스트 모델\n",
    "model_weighted_smote = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "# model_weighted_smote = RandomForestClassifier(n_estimators=200, random_state=42, class_weight={0: 1, 1: 10})\n",
    "\n",
    "model_weighted_smote.fit(X_train, y_train)\n",
    "\n",
    "# 2. 검증 데이터셋에서 예측 수행\n",
    "y_pred_weighted_val = model_weighted_smote.predict(X_val)\n",
    "\n",
    "# 3. 성능 평가\n",
    "accuracy_weighted_val = accuracy_score(y_val, y_pred_weighted_val)\n",
    "classification_rep_weighted_val = classification_report(y_val, y_pred_weighted_val, digits=4)\n",
    "\n",
    "print(\"SMOTE 적용 모델 성능\")\n",
    "print(\"Accuracy:\", accuracy_weighted_val)\n",
    "print(\"Classification Report:\\n\", classification_rep_weighted_val)\n",
    "\n",
    "# 4. 테스트 데이터에서 예측 수행\n",
    "y_pred_test = model_weighted_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 결과를 DataFrame으로 저장\n",
    "submission_same = pd.DataFrame({\n",
    "    'Set ID': Set_ID.values,  # Set ID를 원래대로 유지\n",
    "    'target': y_pred_test\n",
    "})\n",
    "\n",
    "# 기존 0과 1 값을 'AbNormal'과 'Normal'로 변환\n",
    "submission_same['target'] = submission_same['target'].map({0: 'AbNormal', 1: 'Normal'})\n",
    "\n",
    "# submission_same, submission_diff 데이터프레임을 하나로 합치기\n",
    "submission = pd.concat([submission_same, submission_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/lg_capstone/find_abnormal/data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbNormal' 'Normal'] [   45 17288]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(submission_same['target'], return_counts=True)\n",
    "print(unique, counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
