{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diff_test['target'] = 'AbNormal'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing - dam\n",
      "preprocessing - fill1\n",
      "preprocessing - fill2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:396: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill2'].replace(304.8, 305.0, inplace=True) # 304.8을 305.0으로 대체\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:397: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill2'].replace(692.8, 694.0, inplace=True) # 692.8을 694.0으로 대체\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing - autoclave\n",
      "final preprocessing\n",
      "all_data shape: (57746, 137)\n",
      "section 1\n",
      "Equipment_Dam dtype: int32\n",
      "Model.Suffix_Dam dtype: int32\n",
      "Workorder_Dam dtype: int32\n",
      "DISCHARGED SPEED OF RESIN Collect Result_Dam dtype: int64\n",
      "DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam dtype: float64\n",
      "DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam dtype: float64\n",
      "DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam dtype: float64\n",
      "Dispense Volume(Stage1) Collect Result_Dam dtype: float64\n",
      "Dispense Volume(Stage2) Collect Result_Dam dtype: float64\n",
      "Dispense Volume(Stage3) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage1) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage2) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Y AXIS(Stage3) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage1) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage2) Collect Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Z AXIS(Stage3) Collect Result_Dam dtype: float64\n",
      "Head Clean Position Z Collect Result_Dam dtype: float64\n",
      "Head Purge Position Z Collect Result_Dam dtype: float64\n",
      "Head Zero Position Y Collect Result_Dam dtype: float64\n",
      "Head Zero Position Z Collect Result_Dam dtype: float64\n",
      "Machine Tact time Collect Result_Dam dtype: float64\n",
      "PalletID Collect Result_Dam dtype: float64\n",
      "Production Qty Collect Result_Dam dtype: int64\n",
      "Receip No Collect Result_Dam dtype: int64\n",
      "THICKNESS 1 Collect Result_Dam dtype: float64\n",
      "THICKNESS 2 Collect Result_Dam dtype: float64\n",
      "THICKNESS 3 Collect Result_Dam dtype: float64\n",
      "1st Pressure Collect Result_AutoClave dtype: float64\n",
      "1st Pressure 1st Pressure Unit Time_AutoClave dtype: int64\n",
      "2nd Pressure Collect Result_AutoClave dtype: float64\n",
      "2nd Pressure Unit Time_AutoClave dtype: int64\n",
      "3rd Pressure Collect Result_AutoClave dtype: float64\n",
      "3rd Pressure Unit Time_AutoClave dtype: int64\n",
      "Chamber Temp. Collect Result_AutoClave dtype: int64\n",
      "Chamber Temp. Unit Time_AutoClave dtype: int64\n",
      "Chamber Temp. Judge Value_AutoClave dtype: int32\n",
      "GMES_ORIGIN_INSP_JUDGE_CODE Collect Result_AutoClave dtype: int32\n",
      "Head Purge Position Z Collect Result_Fill1 dtype: int64\n",
      "Machine Tact time Collect Result_Fill1 dtype: float64\n",
      "CURE END POSITION Z Collect Result_Fill2 dtype: int64\n",
      "CURE SPEED Collect Result_Fill2 dtype: int64\n",
      "CURE START POSITION Z Collect Result_Fill2 dtype: int64\n",
      "Head Purge Position Z Collect Result_Fill2 dtype: float64\n",
      "Machine Tact time Collect Result_Fill2 dtype: float64\n",
      "Stage1_Distance_Speed_StdDev dtype: float64\n",
      "Stage2_Distance_Speed_StdDev dtype: float64\n",
      "Stage3_Distance_Speed_StdDev dtype: float64\n",
      "Average Stage1 CL Distance Speed Collect Result_Dam dtype: float64\n",
      "Average Stage2 CL Distance Speed Collect Result_Dam dtype: float64\n",
      "Average Stage3 CL Distance Speed Collect Result_Dam dtype: float64\n",
      "Speed_Time_Interaction_Stage1 Result_Dam dtype: float64\n",
      "Speed_Time_Interaction_Stage2 Result_Dam dtype: float64\n",
      "Speed_Time_Interaction_Stage3 Result_Dam dtype: float64\n",
      "Total Speed_Time Result_Dam dtype: float64\n",
      "Total_Dispense_Volume Result_Dam dtype: float64\n",
      "CURE POSITION X Collect Result_Dam dtype: float64\n",
      "CURE POSITION Z Collect Result_Dam dtype: float64\n",
      "CURE DT X Collect Result_Dam dtype: float64\n",
      "CURE DT Z Collect Result_Dam dtype: float64\n",
      "THICKNESS_Range_Collect_Result_Dam dtype: float64\n",
      "HEAD NORMAL COORDINATE Y AXIS(1, 2, 3) dtype: float64\n",
      "HEAD NORMAL COORDINATE Z AXIS(1, 2, 3) dtype: float64\n",
      "HEAD NORMAL COORDINATE Y AXIS_Fill2 dtype: float64\n",
      "HEAD NORMAL COORDINATE Z AXIS_Fill2 dtype: float64\n",
      "section 2\n",
      "section 3\n",
      "train_data shape:  (40413, 73)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:524: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['target'] = train_data['target'].astype(str)  # target 변수\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:525: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['target'] = le.fit_transform(train_data['target'])  # target 변수를 숫자로 변환\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = train_data[column].astype(str)\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = le.transform(train_data[column])\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = train_data[column].astype(str)\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = le.transform(train_data[column])\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = train_data[column].astype(str)\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = le.transform(train_data[column])\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = train_data[column].astype(str)\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = le.transform(train_data[column])\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:529: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = train_data[column].astype(str)\n",
      "c:\\lg_capstone\\find_abnormal\\preprocessing_class.py:531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[column] = le.transform(train_data[column])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section 4\n",
      "train_data shape111:  (40413, 73)\n",
      "train_data shape222:  (40413, 72)\n",
      "features shape:  (40413, 69)\n",
      "scaled_features_train shape111:  (40413, 69)\n",
      "scaled_features_train shape222:  (40413, 69)\n",
      "scaled_features_train shape333:  (40413, 69)\n",
      "section 5\n",
      "scaled_features_train shape:  (40506, 71)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [40506, 40413]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m preprocessing\u001b[38;5;241m.\u001b[39mfill2()\n\u001b[0;32m      8\u001b[0m preprocessing\u001b[38;5;241m.\u001b[39mautoclave()\n\u001b[1;32m----> 9\u001b[0m \u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m X_train \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mX_train\n\u001b[0;32m     11\u001b[0m y_train \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39my_train\n",
      "File \u001b[1;32mc:\\lg_capstone\\find_abnormal\\preprocessing_class.py:594\u001b[0m, in \u001b[0;36mPreprocessing.final_preprocessing\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# 데이터 분리 (학습용 80%, 검증용 20%)\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_features_train shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, scaled_features_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 594\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_features_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;66;03m# SMOTE 적용\u001b[39;00m\n\u001b[0;32m    597\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\lg_capstone\\lg_capstone\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\lg_capstone\\lg_capstone\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2777\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2782\u001b[0m )\n",
      "File \u001b[1;32mc:\\lg_capstone\\lg_capstone\\Lib\\site-packages\\sklearn\\utils\\validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\lg_capstone\\lg_capstone\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [40506, 40413]"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('C:/lg_capstone/find_abnormal/data/train_begin.csv')\n",
    "test = pd.read_csv('C:/lg_capstone/find_abnormal/data/test_begin.csv')\n",
    "\n",
    "preprocessing = Preprocessing(train, test)\n",
    "preprocessing.dam()\n",
    "preprocessing.fill1()\n",
    "preprocessing.fill2()\n",
    "preprocessing.autoclave()\n",
    "preprocessing.final_preprocessing()\n",
    "X_train = preprocessing.X_train\n",
    "y_train = preprocessing.y_train\n",
    "X_val = preprocessing.X_val\n",
    "y_val = preprocessing.y_val\n",
    "\n",
    "X_test = preprocessing.X_test\n",
    "Set_ID = preprocessing.Set_ID\n",
    "\n",
    "submission_diff = preprocessing.submission_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SMOTE를 적용하여 학습한 랜덤 포레스트 모델\n",
    "model_weighted_smote = RandomForestClassifier(n_estimators=200, random_state=42, class_weight={0: 1, 1: 10})\n",
    "model_weighted_smote.fit(X_train, y_train)\n",
    "\n",
    "# 2. 검증 데이터셋에서 예측 수행\n",
    "y_pred_weighted_val = model_weighted_smote.predict(X_val)\n",
    "\n",
    "# 3. 성능 평가\n",
    "accuracy_weighted_val = accuracy_score(y_val, y_pred_weighted_val)\n",
    "classification_rep_weighted_val = classification_report(y_val, y_pred_weighted_val, digits=4)\n",
    "\n",
    "print(\"SMOTE 적용 모델 성능\")\n",
    "print(\"Accuracy:\", accuracy_weighted_val)\n",
    "print(\"Classification Report:\\n\", classification_rep_weighted_val)\n",
    "\n",
    "# 4. 테스트 데이터에서 예측 수행\n",
    "y_pred_test = model_weighted_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 결과를 DataFrame으로 저장\n",
    "result = pd.DataFrame({\n",
    "    'Set ID': Set_ID.values,  # Set ID를 원래대로 유지\n",
    "    'target': y_pred_test\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "print(result.head())\n",
    "\n",
    "print(result.shape)\n",
    "\n",
    "# 기존 0과 1 값을 'AbNormal'과 'Normal'로 변환\n",
    "result['target'] = result['target'].map({0: 'AbNormal', 1: 'Normal'})\n",
    "\n",
    "submission_same = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_same, submission_diff 데이터프레임을 하나로 합치기\n",
    "submission = pd.concat([submission_same, submission_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/lg_capstone/find_abnormal/data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(submission_same['target'], return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_same, submission_diff 데이터프레임을 하나로 합치기\n",
    "submission = pd.concat([submission_same, submission_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('C:/lg_capstone/find_abnormal/data/train_begin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURE START POSITION Z Collect Result_Fill2, CURE END POSITION Z Collect Result_Fill2 열만 추출\n",
    "train_data = train_data[['CURE START POSITION Z Collect Result_Fill2', 'CURE END POSITION Z Collect Result_Fill2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['CURE START POSITION Z Collect Result_Fill2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CURE START POSITION Z Collect Result_Fill2'가 33인 행만 추출\n",
    "train_data_33_33 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 33 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 33)]\n",
    "print(len(train_data_33_33))\n",
    "\n",
    "train_data_33_32 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 33 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 32)]\n",
    "print(len(train_data_33_32))\n",
    "\n",
    "train_data_33_22 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 33 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 22)]\n",
    "print(len(train_data_33_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CURE START POSITION Z Collect Result_Fill2'가 33인 행만 추출\n",
    "train_data_start32 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 32]\n",
    "train_data_start32['CURE END POSITION Z Collect Result_Fill2'].value_counts()\n",
    "\n",
    "train_data_start32_32 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 32 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 32)]\n",
    "print(len(train_data_start32_32))\n",
    "train_data_start32_33 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 32 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 33)]\n",
    "print(len(train_data_start32_33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CURE START POSITION Z Collect Result_Fill2'가 33인 행만 추출\n",
    "train_data_start22 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 22]\n",
    "train_data_start22['CURE END POSITION Z Collect Result_Fill2'].value_counts()\n",
    "\n",
    "train_data_start22_32 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 22 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 32)]\n",
    "print(len(train_data_start22_32))\n",
    "train_data_start22_22 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 22 & (train_data['CURE END POSITION Z Collect Result_Fill2'] == 22)]\n",
    "print(len(train_data_start22_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CURE START POSITION Z Collect Result_Fill2'가 33인 행만 추출\n",
    "train_data_start23 = train_data[train_data['CURE START POSITION Z Collect Result_Fill2'] == 23]\n",
    "train_data_start23['CURE END POSITION Z Collect Result_Fill2'].value_counts()\n",
    "\n",
    "print(train_data_start23['CURE END POSITION Z Collect Result_Fill2'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
